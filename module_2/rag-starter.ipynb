{
 "cells": [
  {
   "cell_type": "code",
   "id": "ae8e2ae0-da25-44e7-ae82-024173150a15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T09:03:02.125263Z",
     "start_time": "2025-06-23T09:03:01.316632Z"
    }
   },
   "source": [
    "import requests \n",
    "\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "57de60e5-b96c-499c-a7cf-0f30fc33b324",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T09:03:02.157007Z",
     "start_time": "2025-06-23T09:03:02.150039Z"
    }
   },
   "source": [
    "documents[2]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - Can I still join the course after the start date?',\n",
       " 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce7d0d18-5c07-4010-9f90-bbd021f110c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.minsearch.Index at 0x7c43acd9fc20>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import minsearch\n",
    "\n",
    "index = minsearch.Index(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")\n",
    "\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa755a08-b98d-4e92-8994-04e6108499d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "openai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b21237c3-80e9-429c-a089-d45428087046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cc5784e-6515-42e5-be62-8fb915df1088",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT: \n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97d35dec-c25f-472d-b961-20d5c30902ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt):\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8602f40b-ad3b-49c9-b3cc-051a79c888bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fd4497b-c5d5-4258-b950-6b35d1af4ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To run Kafka with Java, you need to execute the following command in your project directory:\\n\\n```sh\\njava -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java\\n```\\n\\nIf you\\'re using Python and encounter the \"Module \\'kafka\\' not found\" error when trying to run `producer.py`, you should create a virtual environment, activate it, and install the required packages as per `requirements.txt`:\\n\\n1. Create a virtual environment (run only once):\\n   ```sh\\n   python -m venv env\\n   ```\\n\\n2. Activate the virtual environment:\\n   - On MacOS/Linux:\\n     ```sh\\n     source env/bin/activate\\n     ```\\n   - On Windows:\\n     ```sh\\n     env\\\\Scripts\\\\activate\\n     ```\\n\\n3. Install the necessary packages:\\n   ```sh\\n   pip install -r ../requirements.txt\\n   ```\\n\\nEnsure your Docker images are running if required. To deactivate the virtual environment when done, use:\\n```sh\\ndeactivate\\n```'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag('how do I run kafka?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "385b012f-4905-422d-8d7c-3d542dfe5a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, you can still enroll in the course even if it has already started. You are also eligible to submit the homework assignments. However, make sure to pay attention to the deadlines for turning in the final projects to avoid leaving everything until the last minute.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag('the course has already started, can I still enroll?')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## RAG with vector search ##",
   "id": "e01d4c35125f57a1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T09:28:54.106215Z",
     "start_time": "2025-06-23T09:28:53.512669Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "qd_client = QdrantClient(url=\"http://localhost:6333\")\n",
    "EMBEDDING_DIMENSIONALITY = 512\n",
    "model_handle = \"jinaai/jina-embeddings-v2-small-en\"\n",
    "\n",
    "collection_name = \"zoomcamp-faq\"\n",
    "qd_client.delete_collection(collection_name=collection_name)\n",
    "# Create the collection with specified vector parameters\n",
    "qd_client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=EMBEDDING_DIMENSIONALITY,  # Dimensionality of the vectors\n",
    "        distance=models.Distance.COSINE  # Distance metric for similarity search\n",
    "    )\n",
    ")\n"
   ],
   "id": "92f56d4e7d74d2aa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T09:33:49.312460Z",
     "start_time": "2025-06-23T09:33:49.089880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "qd_client.create_payload_index(\n",
    "    collection_name=collection_name,\n",
    "    field_name=\"course\",\n",
    "    field_schema=\"keyword\"\n",
    ")"
   ],
   "id": "dc4f08d2d7ed1690",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=1, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T09:33:50.601516Z",
     "start_time": "2025-06-23T09:33:50.565786Z"
    }
   },
   "cell_type": "code",
   "source": [
    "points = []\n",
    "for i, doc in enumerate(documents):\n",
    "    text = doc['question'] + ' ' + doc['text']\n",
    "    vector = models.Document(text=text, model=model_handle)\n",
    "\n",
    "    point = models.PointStruct(\n",
    "        id=i,\n",
    "        vector=vector,\n",
    "        payload=doc\n",
    "    )\n",
    "    points.append(point)"
   ],
   "id": "5ec1cb32d375e598",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T09:33:57.602465Z",
     "start_time": "2025-06-23T09:33:57.568634Z"
    }
   },
   "cell_type": "code",
   "source": "points[0]",
   "id": "841ce96b83a93a14",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PointStruct(id=0, vector=Document(text=\"Course - When will the course start? The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\", model='jinaai/jina-embeddings-v2-small-en', options=None), payload={'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\", 'section': 'General course-related questions', 'question': 'Course - When will the course start?', 'course': 'data-engineering-zoomcamp'})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T09:40:02.523020Z",
     "start_time": "2025-06-23T09:37:35.381035Z"
    }
   },
   "cell_type": "code",
   "source": [
    "qd_client.upsert(\n",
    "    collection_name=collection_name,\n",
    "    points=points\n",
    ")"
   ],
   "id": "3a625f949e2ab818",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=2, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8185cd76683de4d1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T09:41:02.807606Z",
     "start_time": "2025-06-23T09:41:02.790694Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#question = 'I just discoverd the course. Can I still join it?'\n",
    "\n",
    "\n",
    "def vector_search(question):\n",
    "    course = 'data-engineering-zoomcamp'\n",
    "    query_points = qd_client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=models.Document(\n",
    "            text=question,\n",
    "            model=model_handle\n",
    "        ),\n",
    "        query_filter=models.Filter(\n",
    "            must=[\n",
    "                models.FieldCondition(\n",
    "                    key=\"course\",\n",
    "                    match=models.MatchValue(value=course)\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "        limit=5,\n",
    "        with_payload=True\n",
    "    )\n",
    "\n",
    "    results = []\n",
    "    for point in query_points.points:\n",
    "        results.append(point.payload)\n",
    "\n",
    "    return results\n",
    "\n"
   ],
   "id": "22f08a002408c74b",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T09:41:05.122033Z",
     "start_time": "2025-06-23T09:41:04.813954Z"
    }
   },
   "cell_type": "code",
   "source": "vector_search('How do i run kafka?')",
   "id": "2a9286a092820457",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Some ehail fees are null and casting them to integer gives Bad int64 value: 0.0 error,\\nSolution:\\nUsing safe_cast returns NULL instead of throwing an error. So use safe_cast from dbt_utils function in the jinja code for casting into integer as follows:\\n{{ dbt_utils.safe_cast(\\'ehail_fee\\',  api.Column.translate_type(\"integer\"))}} as ehail_fee,\\nCan also just use safe_cast(ehail_fee as integer) without relying on dbt_utils.',\n",
       "  'section': 'Module 4: analytics engineering with dbt',\n",
       "  'question': 'Bad int64 value: 0.0 error',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\\n` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\\nexport PYTHONPATH=”${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}”\\nMake sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named \\'py4j\\'` while executing `import pyspark`.\\nFor instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\\nThen the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\\nAdditionally, you can check for the version of ‘py4j’ of the spark you’re using from here and update as mentioned above.\\n~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.',\n",
       "  'section': 'Module 5: pyspark',\n",
       "  'question': \"Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\",\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'If you’re trying to configure CI with Github and on the job’s options you can’t see Run on Pull Requests? on triggers, you have to reconnect with Github using native connection instead clone by SSH. Follow these steps:\\nOn Profile Settings > Linked Accounts connect your Github account with dbt project allowing the permissions asked. More info at https://docs.getdbt.com/docs/collaborate/git/connect-gith\\nDisconnect your current Github’s configuration from Account Settings > Projects (analytics) > Github connection. At the bottom left appears the button Disconnect, press it.\\nOnce we have confirmed the change, we can configure it again. This time, choose Github and it will appear in all repositories which you have allowed to work with dbt. Select your repository and it’s ready.\\nGo to the Deploy > job configuration’s page and go down until Triggers and now you can see the option Run on Pull Requests:',\n",
       "  'section': 'Module 4: analytics engineering with dbt',\n",
       "  'question': 'Dbt deploy + Git CI - Unable to configure Continuous Integration (CI) with Github',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'It is a default behaviour of dbt to append custom schema to initial schema. To override this behaviour simply create a macro named “generate_schema_name.sql”:\\n{% macro generate_schema_name(custom_schema_name, node) -%}\\n{%- set default_schema = target.schema -%}\\n{%- if custom_schema_name is none -%}\\n{{ default_schema }}\\n{%- else -%}\\n{{ custom_schema_name | trim }}\\n{%- endif -%}\\n{%- endmacro %}\\nNow you can override default custom schema in “dbt_project.yml”:',\n",
       "  'section': 'Module 4: analytics engineering with dbt',\n",
       "  'question': 'Why changing the target schema to “marts” actually creates a schema named “dbt_marts” instead?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': \"You will face this issue if you copied and pasted the exact macro directly from data-engineering-zoomcamp repo.\\nBigQuery adapter: Retry attempt 1 of 1 after error: BadRequest('No matching signature for operator CASE for argument types: STRING, INT64, STRING, INT64, STRING, INT64, STRING, INT64, STRING, INT64, STRING, INT64, STRING, NULL at [35:5]; reason: invalidQuery, location: query, message: No matching signature for operator CASE for argument types: STRING, INT64, STRING, INT64, STRING, INT64, STRING, INT64, STRING, INT64, STRING, INT64, STRING, NULL at [35:5]')\\nWhat you’d have to do is to change the data type of the numbers (1, 2, 3 etc.) to text by inserting ‘’, as the initial ‘payment_type’ data type should be string (Note: I extracted and loaded the green trips data using Google BQ Marketplace)\\n{#\\nThis macro returns the description of the payment_type\\n#}\\n{% macro get_payment_type_description(payment_type) -%}\\ncase {{ payment_type }}\\nwhen '1' then 'Credit card'\\nwhen '2' then 'Cash'\\nwhen '3' then 'No charge'\\nwhen '4' then 'Dispute'\\nwhen '5' then 'Unknown'\\nwhen '6' then 'Voided trip'\\nend\\n{%- endmacro %}\",\n",
       "  'section': 'Module 4: analytics engineering with dbt',\n",
       "  'question': 'dbt macro errors with get_payment_type_description(payment_type)',\n",
       "  'course': 'data-engineering-zoomcamp'}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T09:43:41.646920Z",
     "start_time": "2025-06-23T09:43:41.629700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def rag(query):\n",
    "    search_results = vector_search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ],
   "id": "f6d93d439dd87b53",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T09:43:55.193909Z",
     "start_time": "2025-06-23T09:43:54.964341Z"
    }
   },
   "cell_type": "code",
   "source": "rag('how do I run kafka?')",
   "id": "f605892297ee4de1",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'build_prompt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[33], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mrag\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mhow do I run kafka?\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[32], line 3\u001B[0m, in \u001B[0;36mrag\u001B[0;34m(query)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mrag\u001B[39m(query):\n\u001B[1;32m      2\u001B[0m     search_results \u001B[38;5;241m=\u001B[39m vector_search(query)\n\u001B[0;32m----> 3\u001B[0m     prompt \u001B[38;5;241m=\u001B[39m \u001B[43mbuild_prompt\u001B[49m(query, search_results)\n\u001B[1;32m      4\u001B[0m     answer \u001B[38;5;241m=\u001B[39m llm(prompt)\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m answer\n",
      "\u001B[0;31mNameError\u001B[0m: name 'build_prompt' is not defined"
     ]
    }
   ],
   "execution_count": 33
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
